import pandas as pd
def load_raw_data():
    """
    åŠ è½½æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰çš„ JSON æ•°æ®å¹¶åˆå¹¶
    """
    # è·å–åŸå§‹æ•°æ®åœ°å€
    from src import config
    raw_data_path = config.RAW_DATA_DIR

    # è·å–æ‰€æœ‰ JSON æ–‡ä»¶åˆ—è¡¨
    # json_filesåˆ—è¡¨å­˜å‚¨æ‰€æœ‰ JSON æ–‡ä»¶
    json_files = sorted(list(raw_data_path.glob('*.json')))
    print(f"å…±å‘ç° {len(json_files)} ä¸ª JSON æ–‡ä»¶ï¼Œå‡†å¤‡å¼€å§‹åŠ è½½...")

    # ç”¨äºä¸´æ—¶å­˜å‚¨æ¯ä¸ªæ–‡ä»¶çš„ DataFrame
    dfs = [] 

    # å¾ªç¯è¯»å–æ¯ä¸ªæ–‡ä»¶
    for i, file_path in enumerate(json_files, 1):
        try:
            print(f"[{i}/{len(json_files)}] æ­£åœ¨è¯»å–: {file_path.name}")
            # è¯»å–å•ä¸ª JSON
            temp_df = pd.read_json(file_path)
            
            # ä¿ç•™ä½ åŸæœ‰çš„é€»è¾‘ï¼šå±•å¼€ articles å­—æ®µ
            # æ³¨æ„ï¼šå¦‚æœæŸä¸ªæ–‡ä»¶æ˜¯ç©ºçš„æˆ–ç»“æ„ä¸å¯¹ï¼Œè¿™é‡Œå¯èƒ½ä¼šæŠ¥é”™ï¼Œå»ºè®®åŠ ä¸Š try-except
            if 'articles' in temp_df.columns:
                temp_df = temp_df['articles'].apply(pd.Series)
                dfs.append(temp_df)
            else:
                print(f"è­¦å‘Š: æ–‡ä»¶ {file_path.name} ä¸­ä¸åŒ…å« 'articles' å­—æ®µï¼Œå·²è·³è¿‡ã€‚")
                
        except Exception as e:
            print(f"é”™è¯¯: è¯»å–æ–‡ä»¶ {file_path.name} å¤±è´¥. åŸå› : {e}")

    # åˆå¹¶æ‰€æœ‰æ•°æ®
    final_df = pd.concat(dfs, ignore_index=True)
    print(f"åˆå¹¶å®Œæˆï¼Œå…± {len(final_df)} æ¡æ–°é—»ã€‚")

    return final_df

def check_data(df):
    """
    è¯¦ç»†æ£€æŸ¥ DataFrame çš„ç¼ºå¤±å€¼æƒ…å†µï¼Œè¿”å›ç»Ÿè®¡è¡¨
    """
    # 1. è®¡ç®—ç¼ºå¤±å€¼æ•°é‡
    total = df.isnull().sum()
    # 2. è®¡ç®—ç¼ºå¤±å€¼ç™¾åˆ†æ¯”
    percent = (df.isnull().sum() / len(df)) * 100
    # 3. è·å–å„åˆ—æ•°æ®ç±»å‹ (æœ‰åŠ©äºåˆ¤æ–­æ˜¯æ•°å€¼ç¼ºå¤±è¿˜æ˜¯å­—ç¬¦ç¼ºå¤±)
    dtypes = df.dtypes
    # 4. åˆå¹¶æˆä¸€ä¸ªæ–°çš„ DataFrame
    missing_data = pd.concat([total, percent, dtypes], axis=1, keys=['Total', 'Percent (%)', 'Type'])
    # 5. æŒ‰ç¼ºå¤±å€¼æ•°é‡é™åºæ’åˆ—
    missing_data = missing_data.sort_values('Total', ascending=False)
    # 6. åªä¿ç•™æœ‰ç¼ºå¤±å€¼çš„åˆ—ï¼ˆè®©è¾“å‡ºæ›´å¹²å‡€ï¼‰
    missing_data = missing_data[missing_data['Total'] > 0]
    print(f"æ•°æ®æ€»è¡Œæ•°: {len(df)}")
    if missing_data.empty:
        print("å®Œç¾ï¼æ²¡æœ‰å‘ç°ç¼ºå¤±å€¼ã€‚")
    else:
        print(f"å‘ç° {len(missing_data)} ä¸ªåˆ—åŒ…å«ç¼ºå¤±å€¼ï¼š")
        # æ‰“å°ç»“æœï¼ˆå¦‚æœæ˜¯åœ¨ Jupyter ä¸­ï¼Œç›´æ¥è¿”å› missing_data ä¼šæ˜¾ç¤ºæ¼‚äº®çš„è¡¨æ ¼ï¼‰
        display(missing_data) if 'display' in locals() else print(missing_data)
    return missing_data

def load_clean_data():
    """
    åŠ è½½æ¸…ç†åçš„æ•°æ®
    """
    # è·å–åŸå§‹æ•°æ®åœ°å€
    from src import config
    clean_data_path = config.PROCESSED_DATA_DIR / 'cleaned_data.csv'
    classify_data_path = config.PROCESSED_DATA_DIR / 'classify_data.csv'

    # åŠ è½½æ•°æ®
    df = pd.read_csv(clean_data_path)
    df.to_csv(classify_data_path, index=False)

    df = pd.read_csv(classify_data_path)
    return df

def load_classify_data():
    """
    åŠ è½½åˆ†ç±»åçš„æ•°æ®ï¼Œå¹¶è‡ªåŠ¨å‰”é™¤ä¸åœ¨åˆæ³•åˆ†ç±»åˆ—è¡¨ä¸­çš„è¡Œï¼ˆå¦‚ Error æˆ– Noneï¼‰
    """
    import pandas as pd
    from src import config
    
    # 1. å®šä¹‰åˆæ³•åˆ†ç±»æ ‡å‡†
    VALID_CATEGORIES = [
        "ä¸­å°è¾¹ç•Œ/è¾¹å¢ƒé—®é¢˜",
        "è¥¿è—/è¾¾èµ–å–‡å˜›é—®é¢˜",
        "å°æ¹¾é—®é¢˜",
        "ä¸€å¸¦ä¸€è·¯ä¸å‘¨è¾¹åœ°ç¼˜",
        "ä¸­å°ç»è´¸ä¸ç§‘æŠ€",
        "ä¸­å›½ç»æµç°çŠ¶",
        "ä¸­å°å†›åŠ›ä¸å›½é˜²",
        "ä¸­å›½å›½å†…æ”¿æ²»",
        "ä¸­å°åŒè¾¹å…³ç³»",
        "ä¸­å›½å¤–äº¤",
        "ä¸­å°ç­¾è¯ä¸äººæ–‡"
    ]

    classify_data_path = config.PROCESSED_DATA_DIR / 'classify_data.csv'
    result_data_path = config.PROCESSED_DATA_DIR / 'result_data.csv'

    # 2. åŠ è½½æ•°æ®
    df = pd.read_csv(classify_data_path)
    
    # 3. ã€æ–°å¢åŠŸèƒ½ã€‘æ‰§è¡Œè¿‡æ»¤
    original_count = len(df)
    # åªä¿ç•™ category åˆ—çš„å€¼åœ¨ VALID_CATEGORIES åˆ—è¡¨ä¸­çš„è¡Œ
    df = df[df['category'].isin(VALID_CATEGORIES)]
    
    # (å¯é€‰) æ‰“å°æ¸…æ´—æ—¥å¿—
    dropped_count = original_count - len(df)
    if dropped_count > 0:
        print(f"ğŸ§¹ å·²è‡ªåŠ¨å‰”é™¤ {dropped_count} æ¡æ— æ•ˆ/é”™è¯¯åˆ†ç±»æ•°æ® (å‰©ä½™ {len(df)} æ¡)")

    # 4. ä¿å­˜æ¸…æ´—åçš„ç»“æœ
    df.to_csv(result_data_path, index=False, encoding='utf-8-sig')

    # 5. è¿”å›ç»“æœ
    # (é€šå¸¸ä¸éœ€è¦é‡æ–° read_csvï¼Œç›´æ¥è¿”å› df å³å¯ï¼Œä½†ä¸ºäº†ä¿æŒä½ åŸæœ‰é€»è¾‘ä¸åšæ”¹åŠ¨)
    df = pd.read_csv(result_data_path)
    return df