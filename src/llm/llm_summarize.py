from src import config
from concurrent.futures import ThreadPoolExecutor, as_completed
import json
import time
import threading  # 1. å¿…é¡»å¯¼å…¥ threading
import pandas as pd
from tqdm import tqdm
# 2. å¼•å…¥ BadRequestError ä»¥æ•è· 400 é”™è¯¯
from openai import OpenAI, BadRequestError, RateLimitError, APITimeoutError, APIConnectionError

def clean_json_string(text):
    """æ¸…æ´— JSON å­—ç¬¦ä¸²"""
    start = text.find('{')
    end = text.rfind('}')
    if start != -1 and end != -1:
        text = text[start : end + 1]
    return text

def call_llm_summarize(title, content, retries=5):
    """
    ä½¿ç”¨ OpenAI SDK å…¼å®¹æ¨¡å¼è°ƒç”¨ Zenmux/Gemini è¿›è¡Œæ€»ç»“
    """
    client = OpenAI(
        api_key=config.API_KEY,
        base_url=config.API_URL  # ç›´æ¥ä½¿ç”¨å®Œæ•´ URLï¼Œæ— éœ€æ‰‹åŠ¨ strip "/v1"
    )
    
    user_content = f"Headline: {title}\n\nArticle Content: {content}"
    
    for attempt in range(retries):
        try:
            response = client.chat.completions.create(
                model=config.MODEL_NAME, # ç¡®ä¿ config ä¸­å·²æ›´æ–°ä¸º "google/gemini-3-pro-preview"
                messages=[
                    {"role": "system", "content": config.SYSTEM_PROMPT_02},
                    {"role": "user", "content": user_content}
                ],
                temperature=0.1,
                response_format={"type": "json_object"}, # Gemini æ”¯æŒ JSON æ¨¡å¼
                timeout=120,
                stream=False
            )
            
            # 2. å¢åŠ å¯¹ finish_reason çš„æ£€æŸ¥ (Gemini æ•æ„Ÿå†…å®¹è¿‡æ»¤æœºåˆ¶)
            finish_reason = response.choices[0].finish_reason
            if finish_reason == "content_filter":
                print(f"âš ï¸ å†…å®¹å®‰å…¨æ‹¦æˆª (Gemini): {title[:15]}...")
                return None
            
            result_text = response.choices[0].message.content
            
            # ç¡®ä¿ helper å‡½æ•°å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨éœ€è¡¥å……å®šä¹‰
            return json.loads(clean_json_string(result_text))

        # 3. é”™è¯¯å¤„ç† (é€‚é…é€šç”¨ OpenAI åè®®)
        except BadRequestError as e:
            err_msg = str(e)
            # DeepSeek çš„ "Content Exists Risk" åœ¨è¿™é‡Œå¯èƒ½è¡¨ç°ä¸ºå…¶ä»– 400 é”™è¯¯
            # å¦‚æœæ˜¯å†…å®¹å®‰å…¨é—®é¢˜ï¼Œé€šå¸¸ä¸éœ€è¦é‡è¯•
            if 'safety' in err_msg.lower() or 'filter' in err_msg.lower() or 'content' in err_msg.lower():
                print(f"âš ï¸ å†…å®¹æ•æ„Ÿ/è¯·æ±‚æ‹’ç» (è·³è¿‡): {title[:15]}... é”™è¯¯ä¿¡æ¯: {e}")
                return None 
            else:
                print(f"âŒ å‚æ•°é”™è¯¯ (BadRequest): {e}")
                return None
        
        except RateLimitError:
            sleep_time = 5 * (attempt + 1)
            print(f"âš ï¸ 429 é™æµ, ç­‰å¾… {sleep_time}s...")
            time.sleep(sleep_time)
            
        except (APITimeoutError, APIConnectionError) as e:
            print(f"âš ï¸ ç½‘ç»œ/è¶…æ—¶é—®é¢˜: {e}, é‡è¯•ä¸­...")
            time.sleep(2)
            
        except json.JSONDecodeError:
            print(f"âŒ JSON è§£æå¤±è´¥ï¼Œå¯èƒ½æ˜¯æ¨¡å‹è¾“å‡ºæ ¼å¼é”™è¯¯ã€‚é‡è¯•ä¸­...")
            # å¯ä»¥é€‰æ‹©é‡è¯•ï¼Œæˆ–è€…ç›´æ¥ continue
            
        except Exception as e:
            print(f"âŒ æœªçŸ¥å¼‚å¸¸: {e}")
            time.sleep(2)
            
    return None
def llm_summarize_concurrently(
    df, 
    output_csv_path=config.PROCESSED_DATA_DIR / 'result_data.csv', 
    max_workers=None, 
    save_interval=15 
):
    # 4. åˆå§‹åŒ–çº¿ç¨‹é”
    lock = threading.Lock()

    # åˆå§‹åŒ–åˆ—
    required_columns = {
        'Chinese_Entities': None,
        'Indian_Entities': None,
        'Sentiment_Score': None,
        'Summary_CN': None,
        'Summary_EN': None
    }
    
    for col, default_val in required_columns.items():
        if col not in df.columns:
            df[col] = default_val
        
    mask_to_process = (
        df['Summary_CN'].isna() | 
        (df['Summary_CN'] == "") | 
        (df['Summary_CN'] == "Error")
    )
    indices_to_process = df[mask_to_process].index.tolist()
    
    print(f"ğŸ“Š æ€»è¡Œæ•°: {len(df)}")
    print(f"ğŸ”„ æœ¬æ¬¡éœ€å¤„ç†: {len(indices_to_process)} è¡Œ")
    
    if not indices_to_process:
        return df

    if max_workers is None:
        max_workers = min(10, len(indices_to_process))
    
    # æ€§èƒ½ç›‘æ§å˜é‡
    start_time = time.time()
    completed_count = 0
    error_count = 0
    
    def update_and_save(idx, result):
        nonlocal completed_count, error_count
        
        # 5. ä½¿ç”¨å®šä¹‰å¥½çš„ lock
        with lock:
            if result:
                df.at[idx, 'Chinese_Entities'] = result.get('Chinese_Entities')
                df.at[idx, 'Indian_Entities'] = result.get('Indian_Entities')
                df.at[idx, 'Sentiment_Score'] = result.get('Sentiment_Score')
                df.at[idx, 'Summary_CN'] = result.get('Summary_CN')
                df.at[idx, 'Summary_EN'] = result.get('Summary_EN')
            else:
                # ç»“æœä¸º None (åŒ…æ‹¬æ•æ„Ÿå†…å®¹è§¦å‘çš„æƒ…å†µ)
                df.at[idx, 'Summary_CN'] = "Error"
                df.at[idx, 'Summary_EN'] = "Failed/Sensitive"
                df.at[idx, 'Sentiment_Score'] = -999
                error_count += 1
            
            completed_count += 1
            
            if completed_count % save_interval == 0:
                df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')
                elapsed = time.time() - start_time
                rate = completed_count / elapsed
                print(f"\nğŸ’¾ å·²ä¿å­˜: {completed_count}/{len(indices_to_process)} ({rate:.2f} it/s, Err: {error_count})")
    
    print(f"\nğŸš€ å¼€å§‹å¹¶å‘å¤„ç† (Workers: {max_workers})...\n")
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_index = {
            executor.submit(
                call_llm_summarize,           
                df.at[idx, 'title'],         
                df.at[idx, 'content'],
                5
            ): idx 
            for idx in indices_to_process
        }
        
        for future in tqdm(as_completed(future_to_index), total=len(indices_to_process), desc="ğŸ”¥ LLM Processing"):
            idx = future_to_index[future]
            try:
                result = future.result()
                update_and_save(idx, result)     
            except Exception as e:
                print(f"\nâŒ Row {idx} çº¿ç¨‹å¼‚å¸¸: {e}")
                # å¼‚å¸¸å‘ç”Ÿæ—¶çš„å…œåº•ä¿å­˜
                with lock: 
                    df.at[idx, 'Summary_CN'] = "Error"
                    error_count += 1

    df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… å¤„ç†å®Œæˆ! é”™è¯¯æ•°: {error_count}")
    return None